# LLM Coding Failure Modes (Frontier Models Context)

## Frontier focus (why guardrails matter)

- GPT‑5.2 is positioned as a work‑grade model family with improvements in complex workflows, including coding and long‑context tasks, and a more recent August 2025 knowledge cutoff. (OpenAI Academy, Dec 11, 2025)
- Claude Opus 4.5 is positioned as Anthropic’s most capable model for coding, agents, and computer use. (Anthropic, Nov 24, 2025)

These releases push LLMs toward longer‑horizon, multi‑step engineering work. That shifts risk from syntax to *entropy*: excess layers, drift, and unearned abstraction.

## Empirical failure modes (code generation)

### 1) API hallucination and misuse
- LLMs frequently call non‑existent APIs or misuse existing ones in real projects. MARIN (2025) frames this as a persistent issue and proposes dependency‑aware constraints to reduce API hallucinations. It introduces APIHulBench and shows large reductions in hallucination metrics across multiple LLMs.
- De‑Hallucinator (2024) shows that LLMs often “invent” APIs and proposes iterative grounding to increase correct API usage in both Python and JavaScript tasks.

### 2) Repetition / duplicate code blocks
- “Code Copycat Conundrum” (2025) finds repetition is pervasive across 19 LLMs and appears at character, statement, and block levels, reducing readability and quality. The paper proposes DeRep to detect/mitigate these patterns and reports significant improvements in repetition metrics.

### 3) Security blind spots in AI‑generated code
- Veracode’s 2025 research reports high security failure rates in AI‑generated code, including elevated rates in Java and meaningful rates in Python/C#/JavaScript, plus frequent failures on XSS and log injection defenses. The report warns that larger models do not necessarily fix security weaknesses.

## Why this maps directly to ToneGuard Flow Guardrails

- **Flow Specs + Invariants** reduce hallucination risk by anchoring logic to explicit steps and guarantees.
- **Pass‑through wrapper detection** fights repetition and meaningless layers.
- **Lonely abstraction detection** flags pre‑emptive architecture with no proven variation.
- **Placeholder detection** catches unfinished logic before it spreads.

## Sources

- OpenAI Academy: “Introducing GPT‑5.2” (Dec 11, 2025) — https://academy.openai.com/en/home/resources/latest-model
- Anthropic: “Introducing Claude Opus 4.5” (Nov 24, 2025) — https://www.anthropic.com/news/claude-opus-4-5
- Chen et al., “Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware” (arXiv 2505.05057) — https://arxiv.org/abs/2505.05057
- Eghbali & Pradel, “De‑Hallucinator: Mitigating LLM Hallucinations in Code Generation Tasks via Iterative Grounding” (arXiv 2401.01701) — https://arxiv.org/abs/2401.01701
- Liu et al., “Code Copycat Conundrum: Demystifying Repetition in LLM‑based Code Generation” (arXiv 2504.12608) — https://arxiv.org/abs/2504.12608
- Veracode Research: “AI‑Generated Code Poses Major Security Risks…” (Jul 30, 2025) — https://www.businesswire.com/news/home/20250730694951/en/AI-Generated-Code-Poses-Major-Security-Risks-in-Nearly-Half-of-All-Development-Tasks-Veracode-Research-Reveals
